[2022-11-12T11:20:28.895+0000] {processor.py:156} INFO - Started process (PID=37) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:20:28.896+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:20:28.897+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:20:28.897+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:20:29.478+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:20:29.584+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:20:29.584+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:20:29.622+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:20:29.622+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:20:29.654+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.765 seconds
[2022-11-12T11:20:59.891+0000] {processor.py:156} INFO - Started process (PID=66) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:20:59.892+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:20:59.893+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:20:59.893+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:21:00.512+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:21:00.591+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:21:00.590+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:21:00.652+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:21:00.651+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:21:00.697+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.809 seconds
[2022-11-12T11:21:38.086+0000] {processor.py:156} INFO - Started process (PID=93) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:21:38.098+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:21:38.128+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:21:38.128+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:21:47.085+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:21:47.324+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:21:47.323+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:21:47.486+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:21:47.486+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:21:47.642+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 9.565 seconds
[2022-11-12T11:22:17.953+0000] {processor.py:156} INFO - Started process (PID=116) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:22:17.955+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:22:17.956+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:22:17.956+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:22:18.382+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:22:18.449+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:22:18.449+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:22:18.491+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:22:18.491+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:22:18.517+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.571 seconds
[2022-11-12T11:22:48.921+0000] {processor.py:156} INFO - Started process (PID=145) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:22:48.930+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:22:48.932+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:22:48.931+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:22:49.393+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:22:49.467+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:22:49.467+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:22:49.519+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:22:49.519+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:22:49.552+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.643 seconds
[2022-11-12T11:24:32.373+0000] {processor.py:156} INFO - Started process (PID=46) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:24:32.381+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:24:32.384+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:24:32.384+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:24:33.877+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:24:34.014+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:24:34.014+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:24:34.062+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:24:34.062+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:24:34.098+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 1.730 seconds
[2022-11-12T11:25:04.579+0000] {processor.py:156} INFO - Started process (PID=66) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:25:04.580+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:25:04.582+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:25:04.581+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:25:05.035+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:25:05.083+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:25:05.082+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:25:05.117+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:25:05.117+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:25:05.138+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.567 seconds
[2022-11-12T11:25:35.336+0000] {processor.py:156} INFO - Started process (PID=94) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:25:35.337+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:25:35.338+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:25:35.338+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:25:35.743+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:25:35.788+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:25:35.788+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:25:35.829+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:25:35.828+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:25:35.850+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.518 seconds
[2022-11-12T11:26:05.987+0000] {processor.py:156} INFO - Started process (PID=114) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:26:05.988+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:26:05.989+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:26:05.989+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:26:06.353+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:26:06.402+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:26:06.401+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:26:06.434+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:26:06.434+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:26:06.458+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.476 seconds
[2022-11-12T11:26:26.159+0000] {processor.py:156} INFO - Started process (PID=133) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:26:26.160+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:26:26.161+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:26:26.161+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:26:26.431+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:26:26.468+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:26:26.468+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:26:26.495+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:26:26.495+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:26:26.528+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.373 seconds
[2022-11-12T11:26:56.682+0000] {processor.py:156} INFO - Started process (PID=153) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:26:56.685+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:26:56.690+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:26:56.690+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:27:02.152+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:28:08.239+0000] {processor.py:156} INFO - Started process (PID=155) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:28:08.241+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:28:08.243+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:28:08.242+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:28:09.407+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:28:09.512+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:28:09.512+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:28:09.588+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:28:09.588+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:28:09.663+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 1.440 seconds
[2022-11-12T11:28:39.922+0000] {processor.py:156} INFO - Started process (PID=175) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:28:39.930+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:28:39.931+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:28:39.930+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:28:40.217+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:28:40.255+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:28:40.255+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:28:40.283+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:28:40.283+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:28:40.303+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.385 seconds
[2022-11-12T11:29:10.502+0000] {processor.py:156} INFO - Started process (PID=205) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:29:10.503+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:29:10.504+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:29:10.504+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:29:10.934+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:29:10.993+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:29:10.992+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:29:11.044+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:29:11.044+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:29:11.076+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.579 seconds
[2022-11-12T11:29:41.321+0000] {processor.py:156} INFO - Started process (PID=225) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:29:41.323+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:29:41.324+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:29:41.324+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:29:41.601+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:29:41.640+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:29:41.639+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:29:41.671+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:29:41.671+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:29:41.690+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.377 seconds
[2022-11-12T11:30:11.875+0000] {processor.py:156} INFO - Started process (PID=254) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:30:11.883+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:30:11.884+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:30:11.884+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:30:12.209+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:30:12.281+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:30:12.281+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:30:12.307+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:30:12.307+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:30:12.329+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.458 seconds
[2022-11-12T11:30:42.490+0000] {processor.py:156} INFO - Started process (PID=274) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:30:42.491+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:30:42.492+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:30:42.492+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:30:43.190+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:30:43.261+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:30:43.259+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:30:43.311+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:30:43.311+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:30:43.344+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.859 seconds
[2022-11-12T11:31:13.541+0000] {processor.py:156} INFO - Started process (PID=303) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:31:13.542+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:31:13.542+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:31:13.542+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:31:13.784+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:31:13.819+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:31:13.819+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:31:13.847+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:31:13.847+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:31:13.876+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.339 seconds
[2022-11-12T11:31:44.102+0000] {processor.py:156} INFO - Started process (PID=323) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:31:44.112+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:31:44.114+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:31:44.114+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:31:44.407+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:31:44.447+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:31:44.446+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:31:44.475+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:31:44.475+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:31:44.502+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.414 seconds
[2022-11-12T11:32:14.742+0000] {processor.py:156} INFO - Started process (PID=353) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:32:14.743+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:32:14.744+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:32:14.744+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:32:15.013+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:32:15.050+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:32:15.050+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:32:15.077+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:32:15.077+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:32:15.104+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.370 seconds
[2022-11-12T11:32:45.254+0000] {processor.py:156} INFO - Started process (PID=381) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:32:45.254+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:32:45.255+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:32:45.255+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:32:45.670+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:32:45.721+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:32:45.720+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:32:45.770+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:32:45.770+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:32:45.801+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.551 seconds
[2022-11-12T11:33:16.000+0000] {processor.py:156} INFO - Started process (PID=402) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:33:16.001+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:33:16.002+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:33:16.002+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:33:16.294+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:33:16.336+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:33:16.336+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:33:16.367+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:33:16.367+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:33:16.388+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.393 seconds
[2022-11-12T11:33:39.614+0000] {processor.py:156} INFO - Started process (PID=422) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:33:39.618+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:33:39.620+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:33:39.620+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:33:39.649+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:33:39.645+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgre_create_table.py", line 6, in <module>
    sys.path.append(os.path.abspath(".."))
NameError: name 'sys' is not defined
[2022-11-12T11:33:39.651+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:33:39.730+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.129 seconds
[2022-11-12T11:34:09.819+0000] {processor.py:156} INFO - Started process (PID=450) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:34:09.821+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:34:09.823+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:34:09.822+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:34:09.836+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:34:09.835+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgre_create_table.py", line 6, in <module>
    sys.path.append(os.path.abspath(".."))
NameError: name 'sys' is not defined
[2022-11-12T11:34:09.837+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:34:09.861+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.052 seconds
[2022-11-12T11:34:37.050+0000] {processor.py:156} INFO - Started process (PID=469) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:34:37.059+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:34:37.061+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:34:37.061+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:34:37.086+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:34:37.084+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgre_create_table.py", line 6, in <module>
    sys.path.append(os.path.abspath(".."))
NameError: name 'sys' is not defined
[2022-11-12T11:34:37.087+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:34:37.111+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.067 seconds
[2022-11-12T11:34:43.225+0000] {processor.py:156} INFO - Started process (PID=479) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:34:43.226+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:34:43.227+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:34:43.227+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:34:43.238+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:34:43.237+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgre_create_table.py", line 6, in <module>
    sys.path.append(os.path.abspath(".."))
NameError: name 'sys' is not defined
[2022-11-12T11:34:43.239+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:34:43.536+0000] {processor.py:727} INFO - Executed failure callback for <TaskInstance: load_to_dwh_v2.extract_and_clean_data manual__2022-11-12T11:26:37.620584+00:00 [up_for_retry]> in state up_for_retry
[2022-11-12T11:34:43.538+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.318 seconds
[2022-11-12T11:34:53.333+0000] {processor.py:156} INFO - Started process (PID=482) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:34:53.334+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:34:53.335+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:34:53.335+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:34:53.344+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:34:53.343+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgre_create_table.py", line 6, in <module>
    sys.path.append(os.path.abspath(".."))
NameError: name 'sys' is not defined
[2022-11-12T11:34:53.345+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:34:53.670+0000] {processor.py:727} INFO - Executed failure callback for <TaskInstance: load_to_dwh_v2.extract_and_clean_data manual__2022-11-12T11:21:14.929505+00:00 [failed]> in state failed
[2022-11-12T11:34:53.693+0000] {processor.py:727} INFO - Executed failure callback for <TaskInstance: load_to_dwh_v2.extract_and_clean_data manual__2022-11-12T11:21:14.929505+00:00 [failed]> in state failed
[2022-11-12T11:34:53.702+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.374 seconds
[2022-11-12T11:35:03.456+0000] {processor.py:156} INFO - Started process (PID=490) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:35:03.457+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:35:03.458+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:35:03.458+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:35:03.468+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:35:03.466+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgre_create_table.py", line 6, in <module>
    sys.path.append(os.path.abspath(".."))
NameError: name 'sys' is not defined
[2022-11-12T11:35:03.468+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:35:03.730+0000] {processor.py:727} INFO - Executed failure callback for <TaskInstance: load_to_dwh_v2.extract_and_clean_data manual__2022-11-12T11:25:13.413009+00:00 [up_for_retry]> in state up_for_retry
[2022-11-12T11:35:03.747+0000] {processor.py:727} INFO - Executed failure callback for <TaskInstance: load_to_dwh_v2.extract_and_clean_data manual__2022-11-12T11:25:13.413009+00:00 [failed]> in state failed
[2022-11-12T11:35:03.757+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.306 seconds
[2022-11-12T11:35:04.465+0000] {processor.py:156} INFO - Started process (PID=491) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:35:04.466+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:35:04.467+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:35:04.467+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:35:04.478+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:35:04.476+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgre_create_table.py", line 6, in <module>
    sys.path.append(os.path.abspath(".."))
NameError: name 'sys' is not defined
[2022-11-12T11:35:04.479+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:35:04.507+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.047 seconds
[2022-11-12T11:35:13.645+0000] {processor.py:156} INFO - Started process (PID=501) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:35:13.656+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:35:13.659+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:35:13.658+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:35:13.679+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:35:13.676+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgre_create_table.py", line 6, in <module>
    sys.path.append(os.path.abspath(".."))
NameError: name 'sys' is not defined
[2022-11-12T11:35:13.679+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:35:13.793+0000] {processor.py:727} INFO - Executed failure callback for <TaskInstance: load_to_dwh_v2.extract_and_clean_data manual__2022-11-12T11:30:42.459725+00:00 [up_for_retry]> in state up_for_retry
[2022-11-12T11:35:13.795+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.166 seconds
[2022-11-12T11:35:43.963+0000] {processor.py:156} INFO - Started process (PID=529) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:35:43.963+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:35:43.964+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:35:43.964+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:35:43.973+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:35:43.972+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/postgre_create_table.py", line 6, in <module>
    sys.path.append(os.path.abspath(".."))
NameError: name 'sys' is not defined
[2022-11-12T11:35:43.974+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:35:44.000+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.041 seconds
[2022-11-12T11:35:52.025+0000] {processor.py:156} INFO - Started process (PID=537) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:35:52.034+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:35:52.035+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:35:52.035+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:35:52.553+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:35:52.707+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:35:52.706+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:35:52.755+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:35:52.755+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:35:52.807+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.786 seconds
[2022-11-12T11:36:23.046+0000] {processor.py:156} INFO - Started process (PID=560) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:36:23.056+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:36:23.060+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:36:23.059+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:36:23.389+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:36:23.432+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:36:23.432+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:36:23.466+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:36:23.466+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:36:23.490+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.456 seconds
[2022-11-12T11:36:53.650+0000] {processor.py:156} INFO - Started process (PID=589) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:36:53.658+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:36:53.658+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:36:53.658+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:36:53.903+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:36:53.958+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:36:53.958+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:36:53.998+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:36:53.998+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:36:54.028+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.381 seconds
[2022-11-12T11:37:24.224+0000] {processor.py:156} INFO - Started process (PID=609) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:37:24.233+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:37:24.234+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:37:24.234+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:37:24.501+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:37:24.540+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:37:24.539+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:37:24.572+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:37:24.572+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:37:24.602+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.383 seconds
[2022-11-12T11:37:54.794+0000] {processor.py:156} INFO - Started process (PID=638) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:37:54.795+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:37:54.796+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:37:54.796+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:37:55.149+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:37:55.205+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:37:55.204+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:37:55.239+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:37:55.239+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:37:55.262+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.471 seconds
[2022-11-12T11:38:25.459+0000] {processor.py:156} INFO - Started process (PID=667) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:38:25.467+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:38:25.468+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:38:25.468+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:38:25.734+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:38:25.774+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:38:25.774+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:38:25.805+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:38:25.805+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:38:25.834+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.380 seconds
[2022-11-12T11:38:56.033+0000] {processor.py:156} INFO - Started process (PID=686) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:38:56.041+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:38:56.041+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:38:56.041+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:38:56.293+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:38:56.336+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:38:56.335+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:38:56.376+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:38:56.375+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:38:56.404+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.374 seconds
[2022-11-12T11:39:26.568+0000] {processor.py:156} INFO - Started process (PID=715) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:39:26.576+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:39:26.576+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:39:26.576+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:39:26.810+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:39:26.853+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:39:26.853+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:39:26.882+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:39:26.882+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:39:26.911+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.346 seconds
[2022-11-12T11:39:57.120+0000] {processor.py:156} INFO - Started process (PID=744) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:39:57.129+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:39:57.130+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:39:57.130+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:39:57.407+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:39:57.447+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:39:57.446+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:39:57.484+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:39:57.484+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:39:57.508+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.392 seconds
[2022-11-12T11:40:10.617+0000] {processor.py:156} INFO - Started process (PID=755) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:40:10.618+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:40:10.619+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:40:10.619+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:40:10.877+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:40:10.923+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:40:10.922+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:40:10.957+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:40:10.956+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:40:10.992+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.378 seconds
[2022-11-12T11:40:41.155+0000] {processor.py:156} INFO - Started process (PID=775) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:40:41.158+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:40:41.159+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:40:41.159+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:40:41.554+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:40:41.618+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:40:41.616+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:40:41.663+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:40:41.663+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:40:41.705+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.553 seconds
[2022-11-12T11:40:48.786+0000] {processor.py:156} INFO - Started process (PID=786) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:40:48.794+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:40:48.794+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:40:48.794+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:40:49.094+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:40:49.145+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:40:49.145+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:40:49.176+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:40:49.175+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:40:49.202+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.420 seconds
[2022-11-12T11:41:19.638+0000] {processor.py:156} INFO - Started process (PID=804) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:41:19.641+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:41:19.643+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:41:19.642+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:41:20.290+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:41:20.376+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:41:20.376+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:41:20.448+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:41:20.448+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:41:20.494+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.863 seconds
[2022-11-12T11:42:32.307+0000] {processor.py:156} INFO - Started process (PID=46) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:42:32.308+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:42:32.310+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:42:32.309+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:42:33.598+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:42:33.971+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:42:33.970+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:42:34.160+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:42:34.160+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:42:34.240+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 1.959 seconds
[2022-11-12T11:43:04.470+0000] {processor.py:156} INFO - Started process (PID=65) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:43:04.471+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:43:04.471+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:43:04.471+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:43:04.895+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:43:04.929+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:43:04.929+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:43:04.959+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:43:04.959+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:43:04.979+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.513 seconds
[2022-11-12T11:43:35.155+0000] {processor.py:156} INFO - Started process (PID=87) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:43:35.156+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:43:35.157+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:43:35.157+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:43:35.612+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:43:35.655+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:43:35.654+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:43:35.688+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:43:35.687+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:43:35.721+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.570 seconds
[2022-11-12T11:44:49.507+0000] {processor.py:156} INFO - Started process (PID=106) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:44:49.518+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:44:49.535+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:44:49.535+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:44:51.403+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:44:51.457+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:44:51.456+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:44:51.488+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:44:51.488+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:44:51.512+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 2.011 seconds
[2022-11-12T11:44:59.619+0000] {processor.py:156} INFO - Started process (PID=115) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:44:59.621+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:44:59.622+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:44:59.622+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:45:00.259+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:45:00.508+0000] {processor.py:727} INFO - Executed failure callback for <TaskInstance: load_to_dwh_v2.extract_and_clean_data manual__2022-11-12T11:43:30.200309+00:00 [up_for_retry]> in state up_for_retry
[2022-11-12T11:45:00.540+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:45:00.539+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:45:00.565+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:45:00.565+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:45:00.590+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.975 seconds
[2022-11-12T11:45:30.764+0000] {processor.py:156} INFO - Started process (PID=137) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:45:30.765+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:45:30.766+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:45:30.766+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:45:31.105+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:45:31.149+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:45:31.148+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:45:31.184+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:45:31.184+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:45:31.208+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.449 seconds
[2022-11-12T11:46:01.394+0000] {processor.py:156} INFO - Started process (PID=166) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:46:01.396+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:46:01.397+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:46:01.396+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:46:01.694+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:46:01.738+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:46:01.738+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:46:01.772+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:46:01.771+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:46:01.813+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.424 seconds
[2022-11-12T11:46:32.058+0000] {processor.py:156} INFO - Started process (PID=186) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:46:32.062+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:46:32.065+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:46:32.064+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:46:32.399+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:46:32.444+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:46:32.444+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:46:32.483+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:46:32.482+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:46:32.507+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.460 seconds
[2022-11-12T11:46:40.956+0000] {processor.py:156} INFO - Started process (PID=197) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:46:40.957+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:46:40.958+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:46:40.957+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:46:41.263+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:46:41.458+0000] {processor.py:727} INFO - Executed failure callback for <TaskInstance: load_to_dwh_v2.extract_and_clean_data manual__2022-11-12T11:30:42.459725+00:00 [failed]> in state failed
[2022-11-12T11:46:41.493+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:46:41.493+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:46:41.519+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:46:41.519+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:46:41.538+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.586 seconds
[2022-11-12T11:47:11.715+0000] {processor.py:156} INFO - Started process (PID=226) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:47:11.723+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:47:11.724+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:47:11.724+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:47:12.081+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:47:12.145+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:47:12.145+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:47:12.192+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:47:12.191+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:47:12.238+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.527 seconds
[2022-11-12T11:47:42.352+0000] {processor.py:156} INFO - Started process (PID=246) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:47:42.363+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:47:42.365+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:47:42.365+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:47:42.630+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:47:42.673+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:47:42.673+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:47:42.707+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:47:42.707+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:47:42.726+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.385 seconds
[2022-11-12T11:48:12.914+0000] {processor.py:156} INFO - Started process (PID=275) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:48:12.922+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:48:12.923+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:48:12.923+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:48:13.236+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:48:13.285+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:48:13.284+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:48:13.316+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:48:13.316+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:48:13.343+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.431 seconds
[2022-11-12T11:48:43.548+0000] {processor.py:156} INFO - Started process (PID=304) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:48:43.556+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:48:43.557+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:48:43.557+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:48:43.884+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:48:43.926+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:48:43.926+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:48:43.964+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:48:43.964+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:48:44.000+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.456 seconds
[2022-11-12T11:48:46.563+0000] {processor.py:156} INFO - Started process (PID=306) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:48:46.564+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:48:46.565+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:48:46.565+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:48:46.843+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:48:46.885+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:48:46.885+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:48:46.923+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:48:46.923+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:48:46.972+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.411 seconds
[2022-11-12T11:49:17.220+0000] {processor.py:156} INFO - Started process (PID=334) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:49:17.229+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:49:17.230+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:49:17.230+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:49:17.665+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:49:17.732+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:49:17.732+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:49:17.789+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:49:17.789+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:49:17.825+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.608 seconds
[2022-11-12T11:49:47.920+0000] {processor.py:156} INFO - Started process (PID=354) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:49:47.928+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:49:47.929+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:49:47.929+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:49:48.229+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:49:48.279+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:49:48.279+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:49:48.313+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:49:48.313+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:49:48.345+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.431 seconds
[2022-11-12T11:50:18.548+0000] {processor.py:156} INFO - Started process (PID=384) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:50:18.558+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:50:18.561+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:50:18.560+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:50:18.896+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:50:18.955+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:50:18.955+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:50:19.005+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:50:19.005+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:50:19.038+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.501 seconds
[2022-11-12T11:50:20.555+0000] {processor.py:156} INFO - Started process (PID=386) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:50:20.556+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:50:20.558+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:50:20.557+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:50:20.904+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:50:21.023+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:50:21.022+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:50:21.057+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:50:21.057+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:50:21.088+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.537 seconds
[2022-11-12T11:50:51.265+0000] {processor.py:156} INFO - Started process (PID=415) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:50:51.266+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:50:51.267+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:50:51.267+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:50:51.531+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:50:51.575+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:50:51.574+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:50:51.609+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:50:51.609+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:50:51.638+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.377 seconds
[2022-11-12T11:51:21.821+0000] {processor.py:156} INFO - Started process (PID=435) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:51:21.829+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:51:21.830+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:51:21.830+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:51:22.291+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:51:22.353+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:51:22.352+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:51:22.391+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:51:22.391+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:51:22.418+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.600 seconds
[2022-11-12T11:51:52.621+0000] {processor.py:156} INFO - Started process (PID=464) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:51:52.629+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:51:52.631+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:51:52.631+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:51:52.945+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:51:52.999+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:51:52.998+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:51:53.034+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:51:53.034+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:51:53.066+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.450 seconds
[2022-11-12T11:52:23.225+0000] {processor.py:156} INFO - Started process (PID=484) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:52:23.234+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:52:23.235+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:52:23.235+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:52:23.521+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:52:23.561+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:52:23.561+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:52:23.592+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:52:23.592+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:52:23.618+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.397 seconds
[2022-11-12T11:52:53.823+0000] {processor.py:156} INFO - Started process (PID=513) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:52:53.832+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T11:52:53.836+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:52:53.835+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:52:54.262+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T11:52:54.310+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:52:54.309+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T11:52:54.345+0000] {logging_mixin.py:117} INFO - [2022-11-12T11:52:54.345+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T11:52:54.378+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.569 seconds
[2022-11-12T12:55:42.485+0000] {processor.py:156} INFO - Started process (PID=45) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T12:55:42.489+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T12:55:42.490+0000] {logging_mixin.py:117} INFO - [2022-11-12T12:55:42.490+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T12:55:43.607+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T12:55:43.745+0000] {logging_mixin.py:117} INFO - [2022-11-12T12:55:43.745+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T12:55:43.774+0000] {logging_mixin.py:117} INFO - [2022-11-12T12:55:43.774+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T12:55:43.799+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 1.318 seconds
[2022-11-12T12:56:14.007+0000] {processor.py:156} INFO - Started process (PID=64) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T12:56:14.017+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T12:56:14.019+0000] {logging_mixin.py:117} INFO - [2022-11-12T12:56:14.019+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T12:56:14.339+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T12:56:14.406+0000] {logging_mixin.py:117} INFO - [2022-11-12T12:56:14.406+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T12:56:14.448+0000] {logging_mixin.py:117} INFO - [2022-11-12T12:56:14.448+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T12:56:14.477+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.482 seconds
[2022-11-12T12:56:44.672+0000] {processor.py:156} INFO - Started process (PID=93) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T12:56:44.682+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T12:56:44.684+0000] {logging_mixin.py:117} INFO - [2022-11-12T12:56:44.684+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T12:56:44.984+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T12:56:45.028+0000] {logging_mixin.py:117} INFO - [2022-11-12T12:56:45.027+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T12:56:45.058+0000] {logging_mixin.py:117} INFO - [2022-11-12T12:56:45.058+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T12:56:45.086+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.420 seconds
[2022-11-12T12:57:15.273+0000] {processor.py:156} INFO - Started process (PID=122) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T12:57:15.275+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T12:57:15.276+0000] {logging_mixin.py:117} INFO - [2022-11-12T12:57:15.276+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T12:57:15.630+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T12:57:15.685+0000] {logging_mixin.py:117} INFO - [2022-11-12T12:57:15.683+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T12:57:15.728+0000] {logging_mixin.py:117} INFO - [2022-11-12T12:57:15.728+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T12:57:15.753+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.485 seconds
[2022-11-12T12:57:45.986+0000] {processor.py:156} INFO - Started process (PID=141) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T12:57:45.996+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T12:57:45.999+0000] {logging_mixin.py:117} INFO - [2022-11-12T12:57:45.998+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T12:57:46.318+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T12:57:46.359+0000] {logging_mixin.py:117} INFO - [2022-11-12T12:57:46.359+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T12:57:46.394+0000] {logging_mixin.py:117} INFO - [2022-11-12T12:57:46.394+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T12:57:46.423+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.448 seconds
[2022-11-12T12:58:16.639+0000] {processor.py:156} INFO - Started process (PID=169) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T12:58:16.642+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T12:58:16.644+0000] {logging_mixin.py:117} INFO - [2022-11-12T12:58:16.644+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T12:58:16.913+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T12:58:16.952+0000] {logging_mixin.py:117} INFO - [2022-11-12T12:58:16.952+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T12:58:16.983+0000] {logging_mixin.py:117} INFO - [2022-11-12T12:58:16.983+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T12:58:17.005+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.376 seconds
[2022-11-12T12:58:47.211+0000] {processor.py:156} INFO - Started process (PID=196) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T12:58:47.212+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T12:58:47.213+0000] {logging_mixin.py:117} INFO - [2022-11-12T12:58:47.212+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T12:58:47.482+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T12:58:47.523+0000] {logging_mixin.py:117} INFO - [2022-11-12T12:58:47.522+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T12:58:47.555+0000] {logging_mixin.py:117} INFO - [2022-11-12T12:58:47.555+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T12:58:47.586+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.378 seconds
[2022-11-12T12:59:17.809+0000] {processor.py:156} INFO - Started process (PID=218) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T12:59:17.812+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T12:59:17.814+0000] {logging_mixin.py:117} INFO - [2022-11-12T12:59:17.813+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T12:59:18.082+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T12:59:18.121+0000] {logging_mixin.py:117} INFO - [2022-11-12T12:59:18.121+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T12:59:18.151+0000] {logging_mixin.py:117} INFO - [2022-11-12T12:59:18.151+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T12:59:18.181+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.389 seconds
[2022-11-12T12:59:48.403+0000] {processor.py:156} INFO - Started process (PID=247) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T12:59:48.413+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T12:59:48.416+0000] {logging_mixin.py:117} INFO - [2022-11-12T12:59:48.415+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T12:59:48.735+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T12:59:48.778+0000] {logging_mixin.py:117} INFO - [2022-11-12T12:59:48.777+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T12:59:48.807+0000] {logging_mixin.py:117} INFO - [2022-11-12T12:59:48.807+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T12:59:48.839+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.446 seconds
[2022-11-12T13:00:19.080+0000] {processor.py:156} INFO - Started process (PID=268) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:00:19.090+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:00:19.093+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:00:19.092+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:09:52.671+0000] {processor.py:156} INFO - Started process (PID=47) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:09:52.673+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:09:52.675+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:09:52.675+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:09:54.056+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:09:54.177+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:09:54.177+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:09:54.209+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:09:54.209+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:09:54.235+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 1.568 seconds
[2022-11-12T13:10:24.444+0000] {processor.py:156} INFO - Started process (PID=67) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:10:24.454+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:10:24.457+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:10:24.456+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:10:24.747+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:10:24.786+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:10:24.786+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:10:24.815+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:10:24.815+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:10:24.845+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.413 seconds
[2022-11-12T13:10:55.070+0000] {processor.py:156} INFO - Started process (PID=95) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:10:55.080+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:10:55.083+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:10:55.083+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:10:55.561+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:10:55.617+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:10:55.617+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:10:55.661+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:10:55.661+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:10:55.686+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.628 seconds
[2022-11-12T13:11:25.811+0000] {processor.py:156} INFO - Started process (PID=125) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:11:25.819+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:11:25.820+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:11:25.820+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:11:26.216+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:11:26.279+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:11:26.277+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:11:26.329+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:11:26.328+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:11:26.363+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.556 seconds
[2022-11-12T13:11:56.561+0000] {processor.py:156} INFO - Started process (PID=145) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:11:56.562+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:11:56.563+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:11:56.563+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:11:56.892+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:11:56.944+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:11:56.944+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:11:56.989+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:11:56.989+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:11:57.015+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.459 seconds
[2022-11-12T13:12:27.209+0000] {processor.py:156} INFO - Started process (PID=174) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:12:27.210+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:12:27.211+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:12:27.211+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:12:27.559+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:12:27.656+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:12:27.655+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:12:27.704+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:12:27.703+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:12:27.728+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.522 seconds
[2022-11-12T13:12:57.946+0000] {processor.py:156} INFO - Started process (PID=194) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:12:57.954+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:12:57.955+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:12:57.955+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:12:58.218+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:12:58.260+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:12:58.259+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:12:58.293+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:12:58.293+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:12:58.323+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.383 seconds
[2022-11-12T13:13:28.493+0000] {processor.py:156} INFO - Started process (PID=223) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:13:28.494+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:13:28.495+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:13:28.494+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:13:28.761+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:13:28.807+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:13:28.807+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:13:28.836+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:13:28.835+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:13:28.858+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.368 seconds
[2022-11-12T13:13:59.155+0000] {processor.py:156} INFO - Started process (PID=249) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:13:59.163+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:13:59.165+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:13:59.164+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:13:59.460+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:13:59.506+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:13:59.506+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:13:59.539+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:13:59.539+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:13:59.571+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.419 seconds
[2022-11-12T13:14:29.764+0000] {processor.py:156} INFO - Started process (PID=271) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:14:29.773+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:14:29.774+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:14:29.774+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:14:30.044+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:14:30.083+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:14:30.082+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:14:30.114+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:14:30.113+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:14:30.141+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.381 seconds
[2022-11-12T13:14:36.831+0000] {processor.py:156} INFO - Started process (PID=282) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:14:36.834+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:14:36.837+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:14:36.837+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:14:37.225+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:14:37.383+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:14:37.382+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:14:37.434+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:14:37.434+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:14:37.480+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.659 seconds
[2022-11-12T13:15:07.752+0000] {processor.py:156} INFO - Started process (PID=303) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:15:07.761+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:15:07.762+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:15:07.761+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:15:08.032+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:15:08.076+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:15:08.075+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:15:08.112+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:15:08.112+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:15:08.147+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.404 seconds
[2022-11-12T13:15:38.325+0000] {processor.py:156} INFO - Started process (PID=332) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:15:38.329+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:15:38.330+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:15:38.329+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:15:38.716+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:15:38.789+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:15:38.789+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:15:38.830+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:15:38.830+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:15:38.864+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.543 seconds
[2022-11-12T13:16:09.039+0000] {processor.py:156} INFO - Started process (PID=361) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:16:09.047+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:16:09.048+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:16:09.047+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:16:09.363+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:16:09.425+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:16:09.424+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:16:09.475+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:16:09.475+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:16:09.508+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.473 seconds
[2022-11-12T13:16:39.647+0000] {processor.py:156} INFO - Started process (PID=381) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:16:39.647+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:16:39.648+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:16:39.648+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:16:39.930+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:16:39.977+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:16:39.976+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:16:40.009+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:16:40.009+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:16:40.043+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.401 seconds
[2022-11-12T13:17:10.271+0000] {processor.py:156} INFO - Started process (PID=410) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:17:10.281+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:17:10.284+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:17:10.284+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:17:10.576+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:17:10.618+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:17:10.617+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:17:10.647+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:17:10.647+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:17:10.672+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.411 seconds
[2022-11-12T13:17:40.871+0000] {processor.py:156} INFO - Started process (PID=439) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:17:40.879+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:17:40.880+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:17:40.880+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:17:41.185+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:17:41.232+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:17:41.231+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:17:41.268+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:17:41.268+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:17:41.295+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.427 seconds
[2022-11-12T13:18:11.511+0000] {processor.py:156} INFO - Started process (PID=460) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:18:11.519+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:18:11.520+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:18:11.520+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:18:11.795+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:18:11.834+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:18:11.833+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:18:11.864+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:18:11.864+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:18:11.893+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.386 seconds
[2022-11-12T13:18:42.127+0000] {processor.py:156} INFO - Started process (PID=489) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:18:42.135+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:18:42.136+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:18:42.136+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:18:42.437+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:18:42.483+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:18:42.483+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:18:42.516+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:18:42.516+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:18:42.543+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.424 seconds
[2022-11-12T13:19:12.736+0000] {processor.py:156} INFO - Started process (PID=516) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:19:12.744+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:19:12.744+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:19:12.744+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:19:13.071+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:19:13.114+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:19:13.114+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:19:13.142+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:19:13.142+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:19:13.170+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.438 seconds
[2022-11-12T13:19:43.376+0000] {processor.py:156} INFO - Started process (PID=538) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:19:43.383+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:19:43.384+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:19:43.384+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:19:43.726+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:19:43.780+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:19:43.779+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:19:43.826+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:19:43.826+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:19:43.859+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.487 seconds
[2022-11-12T13:20:14.098+0000] {processor.py:156} INFO - Started process (PID=567) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:20:14.106+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:20:14.107+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:20:14.107+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:20:14.370+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:20:14.409+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:20:14.409+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:20:14.440+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:20:14.439+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:20:14.470+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.376 seconds
[2022-11-12T13:20:44.678+0000] {processor.py:156} INFO - Started process (PID=587) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:20:44.686+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:20:44.687+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:20:44.687+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:20:44.968+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:20:45.012+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:20:45.011+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:20:45.043+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:20:45.042+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:20:45.068+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.396 seconds
[2022-11-12T13:21:15.279+0000] {processor.py:156} INFO - Started process (PID=616) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:21:15.287+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:21:15.289+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:21:15.289+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:21:15.592+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:21:15.633+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:21:15.633+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:21:15.672+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:21:15.672+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:21:15.700+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.429 seconds
[2022-11-12T13:21:45.908+0000] {processor.py:156} INFO - Started process (PID=645) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:21:45.910+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:21:45.912+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:21:45.912+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:21:46.189+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:21:46.230+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:21:46.228+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:21:46.260+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:21:46.259+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:21:46.286+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.385 seconds
[2022-11-12T13:22:16.485+0000] {processor.py:156} INFO - Started process (PID=665) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:22:16.494+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:22:16.495+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:22:16.495+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:22:16.817+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:22:16.865+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:22:16.864+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:22:16.897+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:22:16.897+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:22:16.933+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.452 seconds
[2022-11-12T13:22:47.168+0000] {processor.py:156} INFO - Started process (PID=694) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:22:47.177+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:22:47.178+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:22:47.178+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:22:47.436+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:22:47.479+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:22:47.479+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:22:47.513+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:22:47.512+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:22:47.543+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.381 seconds
[2022-11-12T13:23:02.252+0000] {processor.py:156} INFO - Started process (PID=704) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:23:02.253+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:23:02.254+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:23:02.254+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:23:02.543+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:23:02.586+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:23:02.586+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:23:02.620+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:23:02.619+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:23:02.655+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.406 seconds
[2022-11-12T13:23:32.861+0000] {processor.py:156} INFO - Started process (PID=733) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:23:32.869+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:23:32.870+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:23:32.869+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:23:33.122+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:23:33.163+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:23:33.163+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:23:33.193+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:23:33.193+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:23:33.222+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.365 seconds
[2022-11-12T13:24:03.430+0000] {processor.py:156} INFO - Started process (PID=760) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:24:03.438+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:24:03.439+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:24:03.439+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:24:03.834+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:24:03.899+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:24:03.898+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:24:03.942+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:24:03.942+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:24:03.967+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.541 seconds
[2022-11-12T13:24:34.149+0000] {processor.py:156} INFO - Started process (PID=782) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:24:34.150+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:24:34.150+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:24:34.150+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:24:34.410+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:24:34.459+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:24:34.458+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:24:34.496+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:24:34.496+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:24:34.526+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.380 seconds
[2022-11-12T13:25:04.702+0000] {processor.py:156} INFO - Started process (PID=813) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:25:04.712+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:25:04.715+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:25:04.714+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:25:05.073+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:25:05.113+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:25:05.113+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:25:05.141+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:25:05.141+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:25:05.167+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.476 seconds
[2022-11-12T13:25:35.371+0000] {processor.py:156} INFO - Started process (PID=840) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:25:35.379+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:25:35.380+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:25:35.380+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:25:35.705+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:25:35.743+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:25:35.742+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:25:35.777+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:25:35.777+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:25:35.804+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.436 seconds
[2022-11-12T13:26:06.040+0000] {processor.py:156} INFO - Started process (PID=861) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:26:06.050+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:26:06.052+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:26:06.052+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:26:06.347+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:26:06.387+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:26:06.387+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:26:06.427+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:26:06.427+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:26:06.445+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.416 seconds
[2022-11-12T13:26:36.650+0000] {processor.py:156} INFO - Started process (PID=889) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:26:36.658+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:26:36.659+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:26:36.659+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:26:36.991+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:26:37.033+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:26:37.032+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:26:37.063+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:26:37.063+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:26:37.090+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.443 seconds
[2022-11-12T13:27:07.279+0000] {processor.py:156} INFO - Started process (PID=908) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:27:07.280+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:27:07.281+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:27:07.281+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:27:07.551+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:27:07.591+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:27:07.591+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:27:07.620+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:27:07.620+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:27:07.647+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.370 seconds
[2022-11-12T13:27:37.845+0000] {processor.py:156} INFO - Started process (PID=936) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:27:37.846+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:27:37.848+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:27:37.848+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:27:38.247+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:27:38.300+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:27:38.299+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:27:38.335+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:27:38.335+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:27:38.363+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.525 seconds
[2022-11-12T13:28:08.609+0000] {processor.py:156} INFO - Started process (PID=965) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:28:08.619+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:28:08.621+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:28:08.621+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:28:08.903+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:28:08.941+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:28:08.941+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:28:08.970+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:28:08.969+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:28:08.995+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.397 seconds
[2022-11-12T13:28:39.253+0000] {processor.py:156} INFO - Started process (PID=985) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:28:39.262+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:28:39.263+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:28:39.263+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:28:39.518+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:28:39.561+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:28:39.561+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:28:39.590+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:28:39.590+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:28:39.610+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.368 seconds
[2022-11-12T13:29:09.828+0000] {processor.py:156} INFO - Started process (PID=1014) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:29:09.836+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:29:09.837+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:29:09.836+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:29:10.107+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:29:10.145+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:29:10.145+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:29:10.172+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:29:10.172+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:29:10.191+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.367 seconds
[2022-11-12T13:29:40.395+0000] {processor.py:156} INFO - Started process (PID=1044) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:29:40.396+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:29:40.396+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:29:40.396+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:29:40.762+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:29:40.832+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:29:40.832+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:29:40.883+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:29:40.883+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:29:40.909+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.517 seconds
[2022-11-12T13:30:11.156+0000] {processor.py:156} INFO - Started process (PID=1064) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:30:11.166+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:30:11.169+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:30:11.168+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:30:11.452+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:30:11.490+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:30:11.490+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:30:11.517+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:30:11.517+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:30:11.543+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.398 seconds
[2022-11-12T13:30:41.764+0000] {processor.py:156} INFO - Started process (PID=1093) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:30:41.765+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:30:41.765+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:30:41.765+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:30:42.034+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:30:42.073+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:30:42.073+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:30:42.101+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:30:42.101+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:30:42.129+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.370 seconds
[2022-11-12T13:31:12.333+0000] {processor.py:156} INFO - Started process (PID=1122) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:31:12.334+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:31:12.335+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:31:12.335+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:31:12.601+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:31:12.651+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:31:12.651+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:31:12.691+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:31:12.691+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:31:12.714+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.385 seconds
[2022-11-12T13:31:42.957+0000] {processor.py:156} INFO - Started process (PID=1143) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:31:42.959+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:31:42.960+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:31:42.960+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:31:43.275+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:31:43.314+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:31:43.314+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:31:43.341+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:31:43.341+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:31:43.362+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.412 seconds
[2022-11-12T13:32:13.575+0000] {processor.py:156} INFO - Started process (PID=1172) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:32:13.576+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:32:13.576+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:32:13.576+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:32:13.859+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:32:13.895+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:32:13.895+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:32:13.923+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:32:13.923+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:32:13.951+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.380 seconds
[2022-11-12T13:32:44.129+0000] {processor.py:156} INFO - Started process (PID=1202) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:32:44.130+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:32:44.132+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:32:44.131+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:32:44.643+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:32:44.704+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:32:44.704+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:32:44.735+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:32:44.735+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:32:44.758+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.633 seconds
[2022-11-12T13:33:14.957+0000] {processor.py:156} INFO - Started process (PID=1223) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:33:14.958+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:33:14.958+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:33:14.958+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:33:15.239+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:33:15.275+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:33:15.275+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:33:15.305+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:33:15.305+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:33:15.332+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.377 seconds
[2022-11-12T13:33:45.546+0000] {processor.py:156} INFO - Started process (PID=1254) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:33:45.554+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:33:45.554+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:33:45.554+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:33:45.790+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:33:45.836+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:33:45.836+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:33:45.865+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:33:45.865+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:33:45.884+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.342 seconds
[2022-11-12T13:34:16.080+0000] {processor.py:156} INFO - Started process (PID=1282) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:34:16.081+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:34:16.082+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:34:16.081+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:34:16.370+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:34:16.435+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:34:16.435+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:34:16.479+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:34:16.478+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:34:16.503+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.426 seconds
[2022-11-12T13:34:46.712+0000] {processor.py:156} INFO - Started process (PID=1302) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:34:46.722+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:34:46.724+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:34:46.724+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:34:47.042+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:34:47.080+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:34:47.079+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:34:47.108+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:34:47.108+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:34:47.139+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.438 seconds
[2022-11-12T13:35:17.324+0000] {processor.py:156} INFO - Started process (PID=1330) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:35:17.325+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:35:17.326+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:35:17.325+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:35:17.575+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:35:17.612+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:35:17.612+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:35:17.639+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:35:17.638+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:35:17.665+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.345 seconds
[2022-11-12T13:35:47.872+0000] {processor.py:156} INFO - Started process (PID=1359) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:35:47.882+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:35:47.884+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:35:47.884+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:35:48.175+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:35:48.221+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:35:48.220+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:35:48.251+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:35:48.251+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:35:48.283+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.421 seconds
[2022-11-12T13:36:18.500+0000] {processor.py:156} INFO - Started process (PID=1379) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:36:18.508+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:36:18.509+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:36:18.509+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:36:18.810+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:36:18.849+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:36:18.849+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:36:18.877+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:36:18.877+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:36:18.904+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.407 seconds
[2022-11-12T13:36:49.127+0000] {processor.py:156} INFO - Started process (PID=1407) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:36:49.135+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:36:49.136+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:36:49.136+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:36:49.389+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:36:49.426+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:36:49.426+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:36:49.454+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:36:49.454+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:36:49.479+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.356 seconds
[2022-11-12T13:37:19.674+0000] {processor.py:156} INFO - Started process (PID=1436) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:37:19.675+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:37:19.675+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:37:19.675+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:37:19.986+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:37:20.032+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:37:20.031+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:37:20.066+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:37:20.066+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:37:20.094+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.425 seconds
[2022-11-12T13:37:50.280+0000] {processor.py:156} INFO - Started process (PID=1456) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:37:50.288+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:37:50.289+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:37:50.289+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:37:50.556+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:37:50.592+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:37:50.591+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:37:50.620+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:37:50.620+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:37:50.646+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.370 seconds
[2022-11-12T13:38:20.793+0000] {processor.py:156} INFO - Started process (PID=1484) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:38:20.794+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:38:20.795+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:38:20.794+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:38:21.048+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:38:21.088+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:38:21.088+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:38:21.124+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:38:21.124+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:38:21.142+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.353 seconds
[2022-11-12T13:38:51.335+0000] {processor.py:156} INFO - Started process (PID=1513) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:38:51.343+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:38:51.343+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:38:51.343+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:38:51.600+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:38:51.648+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:38:51.647+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:38:51.684+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:38:51.684+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:38:51.708+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.376 seconds
[2022-11-12T13:39:21.830+0000] {processor.py:156} INFO - Started process (PID=1533) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:39:21.838+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:39:21.838+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:39:21.838+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:39:22.082+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:39:22.118+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:39:22.118+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:39:22.153+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:39:22.153+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:39:22.187+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.360 seconds
[2022-11-12T13:39:52.418+0000] {processor.py:156} INFO - Started process (PID=1562) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:39:52.427+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:39:52.429+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:39:52.429+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:39:52.707+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:39:52.746+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:39:52.745+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:39:52.773+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:39:52.772+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:39:52.798+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.385 seconds
[2022-11-12T13:40:22.940+0000] {processor.py:156} INFO - Started process (PID=1590) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:40:22.948+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:40:22.949+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:40:22.949+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:40:23.179+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:40:23.212+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:40:23.212+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:40:23.236+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:40:23.236+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:40:23.259+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.323 seconds
[2022-11-12T13:40:53.450+0000] {processor.py:156} INFO - Started process (PID=1610) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:40:53.459+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:40:53.459+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:40:53.459+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:40:53.720+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:40:53.755+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:40:53.754+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:40:53.781+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:40:53.781+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:40:53.806+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.359 seconds
[2022-11-12T13:41:23.924+0000] {processor.py:156} INFO - Started process (PID=1639) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:41:23.932+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:41:23.932+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:41:23.932+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:41:24.191+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:41:24.228+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:41:24.228+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:41:24.257+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:41:24.256+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:41:24.283+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.362 seconds
[2022-11-12T13:41:54.485+0000] {processor.py:156} INFO - Started process (PID=1669) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:41:54.495+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:41:54.499+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:41:54.498+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:41:54.823+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:41:54.872+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:41:54.872+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:41:54.908+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:41:54.908+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:41:54.938+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.464 seconds
[2022-11-12T13:42:25.149+0000] {processor.py:156} INFO - Started process (PID=1689) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:42:25.150+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:42:25.151+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:42:25.151+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:42:25.438+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:42:25.490+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:42:25.489+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:42:25.531+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:42:25.531+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:42:25.556+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.410 seconds
[2022-11-12T13:42:55.725+0000] {processor.py:156} INFO - Started process (PID=1718) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:42:55.734+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:42:55.735+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:42:55.734+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:42:56.028+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:42:56.066+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:42:56.066+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:42:56.093+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:42:56.093+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:42:56.119+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.399 seconds
[2022-11-12T13:43:26.279+0000] {processor.py:156} INFO - Started process (PID=1747) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:43:26.280+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:43:26.281+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:43:26.281+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:43:26.674+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:43:26.764+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:43:26.764+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:43:26.808+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:43:26.807+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:43:26.835+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.558 seconds
[2022-11-12T13:43:57.008+0000] {processor.py:156} INFO - Started process (PID=1767) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:43:57.009+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:43:57.010+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:43:57.009+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:43:57.297+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:43:57.340+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:43:57.339+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:43:57.376+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:43:57.376+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:43:57.406+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.402 seconds
[2022-11-12T13:44:27.518+0000] {processor.py:156} INFO - Started process (PID=1796) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:44:27.526+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:44:27.527+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:44:27.527+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:44:27.777+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:44:27.819+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:44:27.819+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:44:27.859+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:44:27.859+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:44:27.888+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.372 seconds
[2022-11-12T13:44:58.127+0000] {processor.py:156} INFO - Started process (PID=1817) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:44:58.134+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:44:58.135+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:44:58.135+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:44:58.553+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:44:58.601+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:44:58.601+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:44:58.654+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:44:58.653+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:44:58.694+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.570 seconds
[2022-11-12T13:45:28.882+0000] {processor.py:156} INFO - Started process (PID=1845) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:45:28.891+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:45:28.893+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:45:28.893+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:45:29.211+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:45:29.263+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:45:29.262+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:45:29.306+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:45:29.306+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:45:29.333+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.454 seconds
[2022-11-12T13:45:59.457+0000] {processor.py:156} INFO - Started process (PID=1872) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:45:59.459+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:45:59.459+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:45:59.459+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:45:59.756+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:45:59.807+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:45:59.807+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:45:59.835+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:45:59.835+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:45:59.853+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.399 seconds
[2022-11-12T13:46:30.104+0000] {processor.py:156} INFO - Started process (PID=1893) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:46:30.112+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:46:30.113+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:46:30.113+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:46:30.384+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:46:30.422+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:46:30.421+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:46:30.456+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:46:30.456+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:46:30.490+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.390 seconds
[2022-11-12T13:47:00.633+0000] {processor.py:156} INFO - Started process (PID=1922) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:47:00.634+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:47:00.635+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:47:00.635+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:47:00.911+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:47:00.948+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:47:00.947+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:47:00.974+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:47:00.974+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:47:01.001+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.371 seconds
[2022-11-12T13:47:31.234+0000] {processor.py:156} INFO - Started process (PID=1950) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:47:31.242+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:47:31.242+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:47:31.242+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:47:31.503+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:47:31.541+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:47:31.541+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:47:31.569+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:47:31.569+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:47:31.588+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.357 seconds
[2022-11-12T13:48:01.793+0000] {processor.py:156} INFO - Started process (PID=1969) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:48:01.802+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:48:01.803+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:48:01.803+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:48:02.114+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:48:02.160+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:48:02.159+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:48:02.201+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:48:02.201+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:48:02.229+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.440 seconds
[2022-11-12T13:48:32.430+0000] {processor.py:156} INFO - Started process (PID=1997) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:48:32.431+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:48:32.431+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:48:32.431+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:48:32.771+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:48:32.807+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:48:32.807+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:48:32.834+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:48:32.834+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:48:32.866+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.440 seconds
[2022-11-12T13:49:03.077+0000] {processor.py:156} INFO - Started process (PID=2024) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:49:03.086+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:49:03.086+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:49:03.086+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:49:03.379+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:49:03.418+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:49:03.418+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:49:03.445+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:49:03.445+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:49:03.465+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.393 seconds
[2022-11-12T13:49:33.685+0000] {processor.py:156} INFO - Started process (PID=2045) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:49:33.687+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:49:33.689+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:49:33.688+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:49:34.020+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:49:34.066+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:49:34.066+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:49:34.098+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:49:34.097+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:49:34.122+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.449 seconds
[2022-11-12T13:50:04.305+0000] {processor.py:156} INFO - Started process (PID=2073) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:50:04.306+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:50:04.307+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:50:04.307+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:50:04.659+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:50:04.699+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:50:04.699+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:50:04.726+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:50:04.726+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:50:04.748+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.449 seconds
[2022-11-12T13:50:34.969+0000] {processor.py:156} INFO - Started process (PID=2093) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:50:34.970+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:50:34.970+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:50:34.970+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:50:35.348+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:50:35.412+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:50:35.411+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:50:35.465+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:50:35.465+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:50:35.496+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.530 seconds
[2022-11-12T13:51:05.725+0000] {processor.py:156} INFO - Started process (PID=2122) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:51:05.734+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:51:05.736+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:51:05.736+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:51:06.075+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:51:06.113+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:51:06.113+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:51:06.143+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:51:06.142+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:51:06.161+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.444 seconds
[2022-11-12T13:51:36.318+0000] {processor.py:156} INFO - Started process (PID=2153) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:51:36.318+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:51:36.319+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:51:36.319+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:51:36.648+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:51:36.692+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:51:36.692+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:51:36.724+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:51:36.724+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:51:36.751+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.437 seconds
[2022-11-12T13:52:07.032+0000] {processor.py:156} INFO - Started process (PID=2172) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:52:07.036+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:52:07.038+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:52:07.038+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:52:07.347+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:52:07.389+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:52:07.388+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:52:07.430+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:52:07.430+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:52:07.463+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.450 seconds
[2022-11-12T13:52:37.537+0000] {processor.py:156} INFO - Started process (PID=2201) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:52:37.546+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:52:37.548+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:52:37.547+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:52:37.816+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:52:37.853+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:52:37.853+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:52:37.881+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:52:37.881+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:52:37.899+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.365 seconds
[2022-11-12T13:53:08.124+0000] {processor.py:156} INFO - Started process (PID=2230) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:53:08.134+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:53:08.137+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:53:08.136+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:53:08.428+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:53:08.465+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:53:08.465+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:53:08.493+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:53:08.493+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:53:08.511+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.398 seconds
[2022-11-12T13:53:38.661+0000] {processor.py:156} INFO - Started process (PID=2250) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:53:38.662+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:53:38.663+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:53:38.663+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:53:38.945+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:53:38.995+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:53:38.995+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:53:39.034+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:53:39.033+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:53:39.059+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.402 seconds
[2022-11-12T13:54:09.272+0000] {processor.py:156} INFO - Started process (PID=2279) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:54:09.273+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:54:09.274+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:54:09.273+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:54:09.608+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:54:09.646+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:54:09.645+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:54:09.675+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:54:09.675+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:54:09.694+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.424 seconds
[2022-11-12T13:54:39.917+0000] {processor.py:156} INFO - Started process (PID=2307) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:54:39.927+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:54:39.929+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:54:39.929+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:54:40.228+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:54:40.269+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:54:40.269+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:54:40.297+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:54:40.296+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:54:40.314+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.409 seconds
[2022-11-12T13:55:10.509+0000] {processor.py:156} INFO - Started process (PID=2327) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:55:10.510+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:55:10.511+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:55:10.511+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:55:10.797+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:55:10.837+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:55:10.836+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:55:10.864+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:55:10.864+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:55:10.883+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.379 seconds
[2022-11-12T13:55:41.090+0000] {processor.py:156} INFO - Started process (PID=2356) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:55:41.090+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:55:41.091+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:55:41.091+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:55:41.352+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:55:41.392+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:55:41.392+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:55:41.420+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:55:41.420+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:55:41.446+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.360 seconds
[2022-11-12T13:56:11.683+0000] {processor.py:156} INFO - Started process (PID=2385) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:56:11.693+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:56:11.695+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:56:11.695+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:56:11.979+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:56:12.017+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:56:12.016+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:56:12.045+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:56:12.044+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:56:12.072+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.400 seconds
[2022-11-12T13:56:42.320+0000] {processor.py:156} INFO - Started process (PID=2405) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:56:42.330+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:56:42.332+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:56:42.332+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:56:42.597+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:56:42.636+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:56:42.636+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:56:42.664+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:56:42.664+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:56:42.691+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.382 seconds
[2022-11-12T13:57:12.873+0000] {processor.py:156} INFO - Started process (PID=2434) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:57:12.873+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:57:12.874+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:57:12.874+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:57:13.171+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:57:13.220+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:57:13.220+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:57:13.249+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:57:13.249+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:57:13.274+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.404 seconds
[2022-11-12T13:57:43.448+0000] {processor.py:156} INFO - Started process (PID=2463) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:57:43.456+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:57:43.457+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:57:43.457+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:57:43.757+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:57:43.797+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:57:43.797+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:57:43.825+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:57:43.825+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:57:43.844+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.399 seconds
[2022-11-12T13:58:14.046+0000] {processor.py:156} INFO - Started process (PID=2483) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:58:14.054+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:58:14.055+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:58:14.055+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:58:14.317+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:58:14.357+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:58:14.356+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:58:14.389+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:58:14.389+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:58:14.415+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.371 seconds
[2022-11-12T13:58:44.642+0000] {processor.py:156} INFO - Started process (PID=2513) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:58:44.652+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:58:44.653+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:58:44.653+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:58:44.975+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:58:45.015+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:58:45.015+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:58:45.044+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:58:45.043+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:58:45.072+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.444 seconds
[2022-11-12T13:59:15.303+0000] {processor.py:156} INFO - Started process (PID=2533) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:59:15.304+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:59:15.305+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:59:15.304+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:59:15.610+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:59:15.651+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:59:15.650+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:59:15.702+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:59:15.702+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:59:15.730+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.432 seconds
[2022-11-12T13:59:46.002+0000] {processor.py:156} INFO - Started process (PID=2561) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:59:46.012+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T13:59:46.013+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:59:46.013+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:59:46.302+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T13:59:46.341+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:59:46.341+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T13:59:46.370+0000] {logging_mixin.py:117} INFO - [2022-11-12T13:59:46.369+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T13:59:46.397+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.406 seconds
[2022-11-12T14:00:16.631+0000] {processor.py:156} INFO - Started process (PID=2590) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:00:16.640+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T14:00:16.642+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:00:16.641+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:00:16.926+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:00:16.964+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:00:16.963+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T14:00:16.991+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:00:16.991+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T14:00:17.017+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.390 seconds
[2022-11-12T14:00:47.246+0000] {processor.py:156} INFO - Started process (PID=2610) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:00:47.255+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T14:00:47.258+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:00:47.257+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:00:47.555+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:00:47.599+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:00:47.598+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T14:00:47.628+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:00:47.628+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T14:00:47.653+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.418 seconds
[2022-11-12T14:01:17.895+0000] {processor.py:156} INFO - Started process (PID=2638) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:01:17.904+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T14:01:17.905+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:01:17.904+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:01:18.160+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:01:18.198+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:01:18.198+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T14:01:18.228+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:01:18.227+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T14:01:18.255+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.363 seconds
[2022-11-12T14:01:48.486+0000] {processor.py:156} INFO - Started process (PID=2666) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:01:48.495+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T14:01:48.497+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:01:48.497+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:01:48.768+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:01:48.808+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:01:48.808+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T14:01:48.836+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:01:48.836+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T14:01:48.855+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.383 seconds
[2022-11-12T14:02:19.061+0000] {processor.py:156} INFO - Started process (PID=2686) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:02:19.069+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T14:02:19.069+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:02:19.069+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:02:19.391+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:02:19.435+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:02:19.434+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T14:02:19.466+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:02:19.466+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T14:02:19.498+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.441 seconds
[2022-11-12T14:02:49.740+0000] {processor.py:156} INFO - Started process (PID=2715) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:02:49.742+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T14:02:49.742+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:02:49.742+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:02:50.011+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:02:50.048+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:02:50.048+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T14:02:50.075+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:02:50.075+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T14:02:50.097+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.361 seconds
[2022-11-12T14:03:20.317+0000] {processor.py:156} INFO - Started process (PID=2743) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:03:20.325+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T14:03:20.326+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:03:20.326+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:03:20.589+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:03:20.624+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:03:20.623+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T14:03:20.649+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:03:20.649+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T14:03:20.675+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.361 seconds
[2022-11-12T14:03:50.908+0000] {processor.py:156} INFO - Started process (PID=2764) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:03:50.917+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T14:03:50.919+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:03:50.919+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:03:51.181+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:03:51.218+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:03:51.218+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T14:03:51.246+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:03:51.246+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T14:03:51.277+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.373 seconds
[2022-11-12T14:04:21.520+0000] {processor.py:156} INFO - Started process (PID=2793) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:04:21.528+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T14:04:21.529+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:04:21.528+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:04:21.815+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:04:21.854+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:04:21.854+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T14:04:21.883+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:04:21.883+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T14:04:21.919+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.403 seconds
[2022-11-12T14:04:52.146+0000] {processor.py:156} INFO - Started process (PID=2823) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:04:52.148+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T14:04:52.149+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:04:52.149+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:04:52.402+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:04:52.435+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:04:52.435+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T14:04:52.461+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:04:52.461+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T14:04:52.493+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.354 seconds
[2022-11-12T14:05:22.715+0000] {processor.py:156} INFO - Started process (PID=2843) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:05:22.724+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T14:05:22.725+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:05:22.724+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:05:23.055+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:05:23.102+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:05:23.102+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T14:05:23.131+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:05:23.131+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T14:05:23.159+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.458 seconds
[2022-11-12T14:05:53.398+0000] {processor.py:156} INFO - Started process (PID=2872) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:05:53.408+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T14:05:53.411+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:05:53.411+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:05:53.755+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:05:53.803+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:05:53.803+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T14:05:53.833+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:05:53.833+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T14:05:53.862+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.478 seconds
[2022-11-12T14:06:24.063+0000] {processor.py:156} INFO - Started process (PID=2901) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:06:24.071+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T14:06:24.071+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:06:24.071+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:06:24.306+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:06:24.345+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:06:24.345+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T14:06:24.378+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:06:24.378+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T14:06:24.403+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.343 seconds
[2022-11-12T14:06:54.618+0000] {processor.py:156} INFO - Started process (PID=2920) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:06:54.629+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T14:06:54.631+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:06:54.631+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:06:54.945+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:06:54.986+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:06:54.986+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T14:06:55.013+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:06:55.012+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T14:06:55.039+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.431 seconds
[2022-11-12T14:07:25.220+0000] {processor.py:156} INFO - Started process (PID=2949) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:07:25.228+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T14:07:25.228+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:07:25.228+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:07:25.498+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:07:25.533+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:07:25.533+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T14:07:25.563+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:07:25.563+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T14:07:25.582+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.365 seconds
[2022-11-12T14:07:55.765+0000] {processor.py:156} INFO - Started process (PID=2979) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:07:55.766+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T14:07:55.766+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:07:55.766+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:07:56.114+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:07:56.155+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:07:56.155+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T14:07:56.189+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:07:56.188+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T14:07:56.215+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.453 seconds
[2022-11-12T14:08:26.425+0000] {processor.py:156} INFO - Started process (PID=3000) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:08:26.435+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T14:08:26.437+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:08:26.436+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:08:26.696+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:08:26.740+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:08:26.739+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T14:08:26.781+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:08:26.781+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T14:08:26.816+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.405 seconds
[2022-11-12T14:08:57.039+0000] {processor.py:156} INFO - Started process (PID=3029) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:08:57.047+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T14:08:57.047+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:08:57.047+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:08:57.303+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:08:57.340+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:08:57.339+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T14:08:57.367+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:08:57.366+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T14:08:57.392+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.356 seconds
[2022-11-12T14:09:27.613+0000] {processor.py:156} INFO - Started process (PID=3058) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:09:27.614+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T14:09:27.614+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:09:27.614+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:09:27.860+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:09:27.901+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:09:27.901+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T14:09:27.938+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:09:27.938+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T14:09:27.957+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.348 seconds
[2022-11-12T14:09:58.180+0000] {processor.py:156} INFO - Started process (PID=3078) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:09:58.190+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T14:09:58.192+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:09:58.192+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:09:58.536+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:09:58.574+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:09:58.574+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T14:09:58.601+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:09:58.601+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T14:09:58.633+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.463 seconds
[2022-11-12T14:10:28.828+0000] {processor.py:156} INFO - Started process (PID=3107) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:10:28.829+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T14:10:28.829+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:10:28.829+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:10:29.080+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T14:10:29.118+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:10:29.117+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T14:10:29.146+0000] {logging_mixin.py:117} INFO - [2022-11-12T14:10:29.145+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T14:10:29.168+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.342 seconds
[2022-11-12T19:37:49.307+0000] {processor.py:156} INFO - Started process (PID=46) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T19:37:49.308+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T19:37:49.309+0000] {logging_mixin.py:117} INFO - [2022-11-12T19:37:49.309+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T19:37:50.856+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T19:37:51.039+0000] {logging_mixin.py:117} INFO - [2022-11-12T19:37:51.039+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T19:37:51.080+0000] {logging_mixin.py:117} INFO - [2022-11-12T19:37:51.080+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T19:37:51.128+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 1.826 seconds
[2022-11-12T19:38:21.325+0000] {processor.py:156} INFO - Started process (PID=66) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T19:38:21.333+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T19:38:21.334+0000] {logging_mixin.py:117} INFO - [2022-11-12T19:38:21.333+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T19:38:21.620+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T19:38:21.658+0000] {logging_mixin.py:117} INFO - [2022-11-12T19:38:21.657+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T19:38:21.692+0000] {logging_mixin.py:117} INFO - [2022-11-12T19:38:21.692+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T19:38:21.717+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.398 seconds
[2022-11-12T19:38:51.943+0000] {processor.py:156} INFO - Started process (PID=94) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T19:38:51.944+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T19:38:51.945+0000] {logging_mixin.py:117} INFO - [2022-11-12T19:38:51.945+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T19:38:52.280+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T19:38:52.373+0000] {logging_mixin.py:117} INFO - [2022-11-12T19:38:52.372+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T19:38:52.401+0000] {logging_mixin.py:117} INFO - [2022-11-12T19:38:52.400+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T19:38:52.424+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.484 seconds
[2022-11-12T19:39:22.607+0000] {processor.py:156} INFO - Started process (PID=123) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T19:39:22.615+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T19:39:22.616+0000] {logging_mixin.py:117} INFO - [2022-11-12T19:39:22.616+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T19:39:22.914+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T19:39:22.956+0000] {logging_mixin.py:117} INFO - [2022-11-12T19:39:22.955+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T19:39:22.982+0000] {logging_mixin.py:117} INFO - [2022-11-12T19:39:22.982+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T19:39:23.003+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.398 seconds
[2022-11-12T19:39:53.204+0000] {processor.py:156} INFO - Started process (PID=143) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T19:39:53.213+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T19:39:53.216+0000] {logging_mixin.py:117} INFO - [2022-11-12T19:39:53.215+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T19:39:53.496+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T19:39:53.535+0000] {logging_mixin.py:117} INFO - [2022-11-12T19:39:53.534+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T19:39:53.564+0000] {logging_mixin.py:117} INFO - [2022-11-12T19:39:53.564+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T19:39:53.589+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.389 seconds
[2022-11-12T19:40:23.812+0000] {processor.py:156} INFO - Started process (PID=172) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T19:40:23.814+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T19:40:23.815+0000] {logging_mixin.py:117} INFO - [2022-11-12T19:40:23.815+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T19:40:24.069+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T19:40:24.106+0000] {logging_mixin.py:117} INFO - [2022-11-12T19:40:24.106+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T19:40:24.134+0000] {logging_mixin.py:117} INFO - [2022-11-12T19:40:24.134+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T19:40:24.161+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.356 seconds
[2022-11-12T19:40:54.339+0000] {processor.py:156} INFO - Started process (PID=202) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T19:40:54.340+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T19:40:54.340+0000] {logging_mixin.py:117} INFO - [2022-11-12T19:40:54.340+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T19:40:54.631+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T19:40:54.673+0000] {logging_mixin.py:117} INFO - [2022-11-12T19:40:54.673+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T19:40:54.699+0000] {logging_mixin.py:117} INFO - [2022-11-12T19:40:54.699+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T19:40:54.716+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.382 seconds
[2022-11-12T19:41:24.899+0000] {processor.py:156} INFO - Started process (PID=222) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T19:41:24.899+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T19:41:24.900+0000] {logging_mixin.py:117} INFO - [2022-11-12T19:41:24.900+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T19:41:25.222+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T19:41:25.269+0000] {logging_mixin.py:117} INFO - [2022-11-12T19:41:25.269+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T19:41:25.299+0000] {logging_mixin.py:117} INFO - [2022-11-12T19:41:25.299+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T19:41:25.321+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.425 seconds
[2022-11-12T19:41:55.489+0000] {processor.py:156} INFO - Started process (PID=251) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12T19:41:55.490+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12T19:41:55.490+0000] {logging_mixin.py:117} INFO - [2022-11-12T19:41:55.490+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T19:41:55.763+0000] {processor.py:768} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12T19:41:55.804+0000] {logging_mixin.py:117} INFO - [2022-11-12T19:41:55.804+0000] {dag.py:2573} INFO - Sync 1 DAGs
[2022-11-12T19:41:55.837+0000] {logging_mixin.py:117} INFO - [2022-11-12T19:41:55.837+0000] {dag.py:3328} INFO - Setting next_dagrun for load_to_dwh_v2 to None, run_after=None
[2022-11-12T19:41:55.865+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.379 seconds
[2022-11-12 20:13:23,589] {processor.py:163} INFO - Started process (PID=43) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:13:23,604] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:13:23,605] {logging_mixin.py:109} INFO - [2022-11-12 20:13:23,605] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:13:24,742] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:13:25,511] {logging_mixin.py:109} INFO - [2022-11-12 20:13:25,511] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:13:25,526] {logging_mixin.py:109} INFO - [2022-11-12 20:13:25,525] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:13:25,537] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 1.952 seconds
[2022-11-12 20:13:55,648] {processor.py:163} INFO - Started process (PID=71) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:13:55,659] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:13:55,660] {logging_mixin.py:109} INFO - [2022-11-12 20:13:55,660] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:13:56,064] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:13:56,072] {logging_mixin.py:109} INFO - [2022-11-12 20:13:56,072] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:13:56,084] {logging_mixin.py:109} INFO - [2022-11-12 20:13:56,084] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:13:56,091] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.453 seconds
[2022-11-12 20:14:26,149] {processor.py:163} INFO - Started process (PID=109) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:14:26,149] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:14:26,150] {logging_mixin.py:109} INFO - [2022-11-12 20:14:26,150] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:14:26,539] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:14:26,547] {logging_mixin.py:109} INFO - [2022-11-12 20:14:26,547] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:14:26,558] {logging_mixin.py:109} INFO - [2022-11-12 20:14:26,558] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:14:26,572] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.426 seconds
[2022-11-12 20:14:34,175] {processor.py:163} INFO - Started process (PID=117) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:14:34,177] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:14:34,177] {logging_mixin.py:109} INFO - [2022-11-12 20:14:34,177] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:14:34,577] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:14:34,598] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 14, 34, 589852, tzinfo=Timezone('UTC')), 'duration': 2}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:14:34,613] {logging_mixin.py:109} INFO - [2022-11-12 20:14:34,613] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:14:34,629] {logging_mixin.py:109} INFO - [2022-11-12 20:14:34,629] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:14:34,647] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.474 seconds
[2022-11-12 20:14:44,635] {processor.py:163} INFO - Started process (PID=135) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:14:44,636] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:14:44,636] {logging_mixin.py:109} INFO - [2022-11-12 20:14:44,636] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:14:45,114] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:14:45,143] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 14, 45, 131965, tzinfo=Timezone('UTC')), 'duration': 13}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:14:45,158] {logging_mixin.py:109} INFO - [2022-11-12 20:14:45,157] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:14:45,172] {logging_mixin.py:109} INFO - [2022-11-12 20:14:45,172] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:14:45,181] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.549 seconds
[2022-11-12 20:14:54,732] {processor.py:163} INFO - Started process (PID=153) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:14:54,734] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:14:54,735] {logging_mixin.py:109} INFO - [2022-11-12 20:14:54,734] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:14:55,169] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:14:55,196] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 14, 55, 185627, tzinfo=Timezone('UTC')), 'duration': 23}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:14:55,218] {logging_mixin.py:109} INFO - [2022-11-12 20:14:55,217] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:14:55,233] {logging_mixin.py:109} INFO - [2022-11-12 20:14:55,233] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:14:55,241] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.512 seconds
[2022-11-12 20:15:05,283] {processor.py:163} INFO - Started process (PID=171) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:15:05,292] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:15:05,293] {logging_mixin.py:109} INFO - [2022-11-12 20:15:05,293] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:15:05,779] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:15:05,805] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 15, 5, 795969, tzinfo=Timezone('UTC')), 'duration': 33}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:15:05,823] {logging_mixin.py:109} INFO - [2022-11-12 20:15:05,822] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:15:05,843] {logging_mixin.py:109} INFO - [2022-11-12 20:15:05,843] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:15:05,853] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.575 seconds
[2022-11-12 20:15:15,315] {processor.py:163} INFO - Started process (PID=186) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:15:15,315] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:15:15,316] {logging_mixin.py:109} INFO - [2022-11-12 20:15:15,316] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:15:15,798] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:15:15,827] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 15, 15, 816474, tzinfo=Timezone('UTC')), 'duration': 43}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:15:15,845] {logging_mixin.py:109} INFO - [2022-11-12 20:15:15,844] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:15:15,863] {logging_mixin.py:109} INFO - [2022-11-12 20:15:15,863] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:15:15,874] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.561 seconds
[2022-11-12 20:15:25,356] {processor.py:163} INFO - Started process (PID=197) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:15:25,357] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:15:25,357] {logging_mixin.py:109} INFO - [2022-11-12 20:15:25,357] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:15:25,770] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:15:25,790] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 15, 25, 784130, tzinfo=Timezone('UTC')), 'duration': 53}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:15:25,810] {logging_mixin.py:109} INFO - [2022-11-12 20:15:25,810] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:15:25,825] {logging_mixin.py:109} INFO - [2022-11-12 20:15:25,825] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:15:25,840] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.488 seconds
[2022-11-12 20:15:35,385] {processor.py:163} INFO - Started process (PID=215) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:15:35,385] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:15:35,386] {logging_mixin.py:109} INFO - [2022-11-12 20:15:35,386] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:15:35,869] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:15:35,889] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 15, 35, 883182, tzinfo=Timezone('UTC')), 'duration': 63}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:15:35,904] {logging_mixin.py:109} INFO - [2022-11-12 20:15:35,904] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:15:35,921] {logging_mixin.py:109} INFO - [2022-11-12 20:15:35,921] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:15:35,939] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.557 seconds
[2022-11-12 20:15:45,910] {processor.py:163} INFO - Started process (PID=234) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:15:45,911] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:15:45,912] {logging_mixin.py:109} INFO - [2022-11-12 20:15:45,912] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:15:46,335] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:15:46,364] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 15, 46, 357098, tzinfo=Timezone('UTC')), 'duration': 74}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:15:46,381] {logging_mixin.py:109} INFO - [2022-11-12 20:15:46,381] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:15:46,394] {logging_mixin.py:109} INFO - [2022-11-12 20:15:46,394] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:15:46,401] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.493 seconds
[2022-11-12 20:15:56,007] {processor.py:163} INFO - Started process (PID=252) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:15:56,015] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:15:56,016] {logging_mixin.py:109} INFO - [2022-11-12 20:15:56,016] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:15:56,467] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:15:56,492] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 15, 56, 482514, tzinfo=Timezone('UTC')), 'duration': 84}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:15:56,505] {logging_mixin.py:109} INFO - [2022-11-12 20:15:56,505] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:15:56,517] {logging_mixin.py:109} INFO - [2022-11-12 20:15:56,517] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:15:56,524] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.520 seconds
[2022-11-12 20:16:06,470] {processor.py:163} INFO - Started process (PID=269) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:16:06,478] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:16:06,479] {logging_mixin.py:109} INFO - [2022-11-12 20:16:06,479] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:16:06,914] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:16:06,935] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 16, 6, 927612, tzinfo=Timezone('UTC')), 'duration': 95}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:16:06,951] {logging_mixin.py:109} INFO - [2022-11-12 20:16:06,951] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:16:06,965] {logging_mixin.py:109} INFO - [2022-11-12 20:16:06,965] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:16:06,972] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.504 seconds
[2022-11-12 20:16:16,597] {processor.py:163} INFO - Started process (PID=278) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:16:16,605] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:16:16,606] {logging_mixin.py:109} INFO - [2022-11-12 20:16:16,606] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:16:17,021] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:16:17,052] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 16, 17, 36329, tzinfo=Timezone('UTC')), 'duration': 105}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:16:17,065] {logging_mixin.py:109} INFO - [2022-11-12 20:16:17,064] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:16:17,075] {logging_mixin.py:109} INFO - [2022-11-12 20:16:17,075] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:16:17,082] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.489 seconds
[2022-11-12 20:16:27,075] {processor.py:163} INFO - Started process (PID=295) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:16:27,085] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:16:27,087] {logging_mixin.py:109} INFO - [2022-11-12 20:16:27,087] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:16:27,695] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:16:27,716] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 16, 27, 708605, tzinfo=Timezone('UTC')), 'duration': 115}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:16:27,730] {logging_mixin.py:109} INFO - [2022-11-12 20:16:27,730] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:16:27,742] {logging_mixin.py:109} INFO - [2022-11-12 20:16:27,742] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:16:27,749] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.684 seconds
[2022-11-12 20:16:37,151] {processor.py:163} INFO - Started process (PID=313) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:16:37,152] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:16:37,153] {logging_mixin.py:109} INFO - [2022-11-12 20:16:37,153] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:16:37,684] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:16:37,726] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 16, 37, 711682, tzinfo=Timezone('UTC')), 'duration': 125}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:16:37,742] {logging_mixin.py:109} INFO - [2022-11-12 20:16:37,742] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:16:37,760] {logging_mixin.py:109} INFO - [2022-11-12 20:16:37,760] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:16:37,773] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.627 seconds
[2022-11-12 20:16:47,822] {processor.py:163} INFO - Started process (PID=331) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:16:47,823] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:16:47,824] {logging_mixin.py:109} INFO - [2022-11-12 20:16:47,824] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:16:48,264] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:16:48,287] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 16, 48, 278873, tzinfo=Timezone('UTC')), 'duration': 136}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:16:48,301] {logging_mixin.py:109} INFO - [2022-11-12 20:16:48,301] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:16:48,311] {logging_mixin.py:109} INFO - [2022-11-12 20:16:48,311] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:16:48,326] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.506 seconds
[2022-11-12 20:16:57,857] {processor.py:163} INFO - Started process (PID=339) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:16:57,858] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:16:57,859] {logging_mixin.py:109} INFO - [2022-11-12 20:16:57,859] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:16:58,277] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:16:58,298] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 16, 58, 291363, tzinfo=Timezone('UTC')), 'duration': 146}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:16:58,313] {logging_mixin.py:109} INFO - [2022-11-12 20:16:58,313] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:16:58,324] {logging_mixin.py:109} INFO - [2022-11-12 20:16:58,324] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:16:58,332] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.478 seconds
[2022-11-12 20:17:07,891] {processor.py:163} INFO - Started process (PID=357) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:17:07,892] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:17:07,893] {logging_mixin.py:109} INFO - [2022-11-12 20:17:07,893] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:17:08,327] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:17:08,352] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 17, 8, 345208, tzinfo=Timezone('UTC')), 'duration': 156}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:17:08,364] {logging_mixin.py:109} INFO - [2022-11-12 20:17:08,364] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:17:08,375] {logging_mixin.py:109} INFO - [2022-11-12 20:17:08,375] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:17:08,389] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.500 seconds
[2022-11-12 20:17:18,432] {processor.py:163} INFO - Started process (PID=375) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:17:18,434] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:17:18,435] {logging_mixin.py:109} INFO - [2022-11-12 20:17:18,435] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:17:18,818] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:17:18,839] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 17, 18, 831619, tzinfo=Timezone('UTC')), 'duration': 166}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:17:18,852] {logging_mixin.py:109} INFO - [2022-11-12 20:17:18,852] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:17:18,864] {logging_mixin.py:109} INFO - [2022-11-12 20:17:18,864] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:17:18,878] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.452 seconds
[2022-11-12 20:17:28,499] {processor.py:163} INFO - Started process (PID=393) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:17:28,501] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:17:28,502] {logging_mixin.py:109} INFO - [2022-11-12 20:17:28,502] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:17:28,899] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:17:28,930] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 17, 28, 913963, tzinfo=Timezone('UTC')), 'duration': 177}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:17:28,943] {logging_mixin.py:109} INFO - [2022-11-12 20:17:28,943] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:17:28,956] {logging_mixin.py:109} INFO - [2022-11-12 20:17:28,956] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:17:28,963] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.471 seconds
[2022-11-12 20:17:38,942] {processor.py:163} INFO - Started process (PID=411) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:17:38,942] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:17:38,943] {logging_mixin.py:109} INFO - [2022-11-12 20:17:38,943] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:17:39,377] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:17:39,423] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 17, 39, 400788, tzinfo=Timezone('UTC')), 'duration': 187}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:17:39,439] {logging_mixin.py:109} INFO - [2022-11-12 20:17:39,439] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:17:39,450] {logging_mixin.py:109} INFO - [2022-11-12 20:17:39,450] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:17:39,457] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.518 seconds
[2022-11-12 20:17:49,021] {processor.py:163} INFO - Started process (PID=419) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:17:49,022] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:17:49,022] {logging_mixin.py:109} INFO - [2022-11-12 20:17:49,022] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:17:49,434] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:17:49,472] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 17, 49, 449634, tzinfo=Timezone('UTC')), 'duration': 197}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:17:49,489] {logging_mixin.py:109} INFO - [2022-11-12 20:17:49,489] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:17:49,504] {logging_mixin.py:109} INFO - [2022-11-12 20:17:49,504] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:17:49,512] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.493 seconds
[2022-11-12 20:17:59,561] {processor.py:163} INFO - Started process (PID=438) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:17:59,562] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:17:59,563] {logging_mixin.py:109} INFO - [2022-11-12 20:17:59,563] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:18:00,133] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:18:00,166] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 18, 0, 149406, tzinfo=Timezone('UTC')), 'duration': 208}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:18:00,180] {logging_mixin.py:109} INFO - [2022-11-12 20:18:00,180] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:18:00,193] {logging_mixin.py:109} INFO - [2022-11-12 20:18:00,192] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:18:00,200] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.642 seconds
[2022-11-12 20:18:09,597] {processor.py:163} INFO - Started process (PID=455) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:18:09,598] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:18:09,598] {logging_mixin.py:109} INFO - [2022-11-12 20:18:09,598] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:18:09,967] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:18:09,999] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 18, 9, 980594, tzinfo=Timezone('UTC')), 'duration': 218}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:18:10,015] {logging_mixin.py:109} INFO - [2022-11-12 20:18:10,015] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:18:10,026] {logging_mixin.py:109} INFO - [2022-11-12 20:18:10,025] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:18:10,033] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.439 seconds
[2022-11-12 20:18:19,643] {processor.py:163} INFO - Started process (PID=473) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:18:19,644] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:18:19,645] {logging_mixin.py:109} INFO - [2022-11-12 20:18:19,645] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:18:20,007] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:18:20,026] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 18, 20, 20399, tzinfo=Timezone('UTC')), 'duration': 228}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:18:20,039] {logging_mixin.py:109} INFO - [2022-11-12 20:18:20,039] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:18:20,049] {logging_mixin.py:109} INFO - [2022-11-12 20:18:20,049] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:18:20,064] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.426 seconds
[2022-11-12 20:18:30,154] {processor.py:163} INFO - Started process (PID=491) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:18:30,155] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:18:30,155] {logging_mixin.py:109} INFO - [2022-11-12 20:18:30,155] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:18:30,774] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:18:30,825] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 18, 30, 809603, tzinfo=Timezone('UTC')), 'duration': 238}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:18:30,840] {logging_mixin.py:109} INFO - [2022-11-12 20:18:30,840] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:18:30,859] {logging_mixin.py:109} INFO - [2022-11-12 20:18:30,859] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:18:30,875] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.724 seconds
[2022-11-12 20:18:40,179] {processor.py:163} INFO - Started process (PID=499) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:18:40,179] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:18:40,180] {logging_mixin.py:109} INFO - [2022-11-12 20:18:40,180] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:18:40,541] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:18:40,561] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 18, 40, 554112, tzinfo=Timezone('UTC')), 'duration': 248}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:18:40,573] {logging_mixin.py:109} INFO - [2022-11-12 20:18:40,573] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:18:40,583] {logging_mixin.py:109} INFO - [2022-11-12 20:18:40,583] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:18:40,590] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.414 seconds
[2022-11-12 20:18:50,211] {processor.py:163} INFO - Started process (PID=517) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:18:50,212] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:18:50,212] {logging_mixin.py:109} INFO - [2022-11-12 20:18:50,212] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:18:50,793] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:18:50,824] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 18, 50, 812557, tzinfo=Timezone('UTC')), 'duration': 258}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:18:50,841] {logging_mixin.py:109} INFO - [2022-11-12 20:18:50,841] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:18:50,858] {logging_mixin.py:109} INFO - [2022-11-12 20:18:50,858] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:18:50,868] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.660 seconds
[2022-11-12 20:19:00,653] {processor.py:163} INFO - Started process (PID=535) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:19:00,654] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:19:00,655] {logging_mixin.py:109} INFO - [2022-11-12 20:19:00,655] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:19:01,217] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:19:01,238] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 19, 1, 230846, tzinfo=Timezone('UTC')), 'duration': 269}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:19:01,250] {logging_mixin.py:109} INFO - [2022-11-12 20:19:01,250] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:19:01,260] {logging_mixin.py:109} INFO - [2022-11-12 20:19:01,260] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:19:01,267] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.618 seconds
[2022-11-12 20:19:10,941] {processor.py:163} INFO - Started process (PID=553) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:19:10,949] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:19:10,950] {logging_mixin.py:109} INFO - [2022-11-12 20:19:10,950] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:19:11,429] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:19:11,448] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 19, 11, 442233, tzinfo=Timezone('UTC')), 'duration': 279}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:19:11,461] {logging_mixin.py:109} INFO - [2022-11-12 20:19:11,461] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:19:11,472] {logging_mixin.py:109} INFO - [2022-11-12 20:19:11,472] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:19:11,487] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.550 seconds
[2022-11-12 20:19:21,328] {processor.py:163} INFO - Started process (PID=571) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:19:21,329] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:19:21,330] {logging_mixin.py:109} INFO - [2022-11-12 20:19:21,329] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:19:21,777] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:19:21,798] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 19, 21, 791215, tzinfo=Timezone('UTC')), 'duration': 289}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:19:21,816] {logging_mixin.py:109} INFO - [2022-11-12 20:19:21,816] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:19:21,833] {logging_mixin.py:109} INFO - [2022-11-12 20:19:21,833] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:19:21,849] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.523 seconds
[2022-11-12 20:19:31,581] {processor.py:163} INFO - Started process (PID=579) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:19:31,583] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:19:31,584] {logging_mixin.py:109} INFO - [2022-11-12 20:19:31,584] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:19:32,101] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:19:32,124] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 19, 32, 115820, tzinfo=Timezone('UTC')), 'duration': 300}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:19:32,137] {logging_mixin.py:109} INFO - [2022-11-12 20:19:32,137] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:19:32,148] {logging_mixin.py:109} INFO - [2022-11-12 20:19:32,148] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:19:32,155] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.581 seconds
[2022-11-12 20:19:41,912] {processor.py:163} INFO - Started process (PID=597) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:19:41,913] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:19:41,913] {logging_mixin.py:109} INFO - [2022-11-12 20:19:41,913] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:19:42,364] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:19:42,384] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 19, 42, 376703, tzinfo=Timezone('UTC')), 'duration': 310}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:19:42,398] {logging_mixin.py:109} INFO - [2022-11-12 20:19:42,398] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:19:42,407] {logging_mixin.py:109} INFO - [2022-11-12 20:19:42,407] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:19:42,413] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.504 seconds
[2022-11-12 20:19:52,217] {processor.py:163} INFO - Started process (PID=616) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:19:52,226] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:19:52,226] {logging_mixin.py:109} INFO - [2022-11-12 20:19:52,226] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:19:52,637] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:19:52,661] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 19, 52, 652868, tzinfo=Timezone('UTC')), 'duration': 320}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:19:52,674] {logging_mixin.py:109} INFO - [2022-11-12 20:19:52,674] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:19:52,686] {logging_mixin.py:109} INFO - [2022-11-12 20:19:52,686] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:19:52,700] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.486 seconds
[2022-11-12 20:20:02,469] {processor.py:163} INFO - Started process (PID=634) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:20:02,470] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:20:02,470] {logging_mixin.py:109} INFO - [2022-11-12 20:20:02,470] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:20:02,872] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:20:02,895] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 20, 2, 887990, tzinfo=Timezone('UTC')), 'duration': 330}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:20:02,909] {logging_mixin.py:109} INFO - [2022-11-12 20:20:02,909] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:20:02,918] {logging_mixin.py:109} INFO - [2022-11-12 20:20:02,918] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:20:02,925] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.458 seconds
[2022-11-12 20:20:12,770] {processor.py:163} INFO - Started process (PID=653) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:20:12,771] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:20:12,772] {logging_mixin.py:109} INFO - [2022-11-12 20:20:12,772] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:20:13,142] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:20:13,163] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 20, 13, 155690, tzinfo=Timezone('UTC')), 'duration': 341}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:20:13,176] {logging_mixin.py:109} INFO - [2022-11-12 20:20:13,176] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:20:13,186] {logging_mixin.py:109} INFO - [2022-11-12 20:20:13,186] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:20:13,201] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.434 seconds
[2022-11-12 20:20:22,994] {processor.py:163} INFO - Started process (PID=670) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:20:22,995] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:20:22,995] {logging_mixin.py:109} INFO - [2022-11-12 20:20:22,995] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:20:23,466] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:20:23,493] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 20, 23, 482935, tzinfo=Timezone('UTC')), 'duration': 351}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:20:23,504] {logging_mixin.py:109} INFO - [2022-11-12 20:20:23,504] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:20:23,514] {logging_mixin.py:109} INFO - [2022-11-12 20:20:23,514] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:20:23,521] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.530 seconds
[2022-11-12 20:20:33,294] {processor.py:163} INFO - Started process (PID=679) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:20:33,302] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:20:33,303] {logging_mixin.py:109} INFO - [2022-11-12 20:20:33,303] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:20:33,710] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:20:33,732] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 20, 33, 723887, tzinfo=Timezone('UTC')), 'duration': 361}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:20:33,744] {logging_mixin.py:109} INFO - [2022-11-12 20:20:33,744] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:20:33,755] {logging_mixin.py:109} INFO - [2022-11-12 20:20:33,755] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:20:33,770] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.479 seconds
[2022-11-12 20:20:43,599] {processor.py:163} INFO - Started process (PID=697) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:20:43,600] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:20:43,601] {logging_mixin.py:109} INFO - [2022-11-12 20:20:43,601] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:20:43,997] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:20:44,017] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 20, 44, 10850, tzinfo=Timezone('UTC')), 'duration': 372}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:20:44,030] {logging_mixin.py:109} INFO - [2022-11-12 20:20:44,029] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:20:44,040] {logging_mixin.py:109} INFO - [2022-11-12 20:20:44,040] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:20:44,055] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.460 seconds
[2022-11-12 20:20:53,846] {processor.py:163} INFO - Started process (PID=715) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:20:53,847] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:20:53,847] {logging_mixin.py:109} INFO - [2022-11-12 20:20:53,847] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:20:54,241] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:20:54,262] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 20, 54, 254711, tzinfo=Timezone('UTC')), 'duration': 382}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:20:54,276] {logging_mixin.py:109} INFO - [2022-11-12 20:20:54,276] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:20:54,286] {logging_mixin.py:109} INFO - [2022-11-12 20:20:54,286] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:20:54,301] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.458 seconds
[2022-11-12 20:21:04,127] {processor.py:163} INFO - Started process (PID=733) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:21:04,129] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:21:04,129] {logging_mixin.py:109} INFO - [2022-11-12 20:21:04,129] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:21:04,543] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:21:04,561] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 21, 4, 554653, tzinfo=Timezone('UTC')), 'duration': 392}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:21:04,572] {logging_mixin.py:109} INFO - [2022-11-12 20:21:04,572] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:21:04,581] {logging_mixin.py:109} INFO - [2022-11-12 20:21:04,581] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:21:04,587] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.463 seconds
[2022-11-12 20:21:14,372] {processor.py:163} INFO - Started process (PID=751) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:21:14,373] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:21:14,373] {logging_mixin.py:109} INFO - [2022-11-12 20:21:14,373] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:21:14,797] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:21:14,818] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 21, 14, 810230, tzinfo=Timezone('UTC')), 'duration': 402}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:21:14,832] {logging_mixin.py:109} INFO - [2022-11-12 20:21:14,832] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:21:14,841] {logging_mixin.py:109} INFO - [2022-11-12 20:21:14,841] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:21:14,847] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.477 seconds
[2022-11-12 20:21:24,700] {processor.py:163} INFO - Started process (PID=759) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:21:24,701] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:21:24,702] {logging_mixin.py:109} INFO - [2022-11-12 20:21:24,701] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:21:25,097] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:21:25,118] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 21, 25, 110642, tzinfo=Timezone('UTC')), 'duration': 413}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:21:25,131] {logging_mixin.py:109} INFO - [2022-11-12 20:21:25,131] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:21:25,142] {logging_mixin.py:109} INFO - [2022-11-12 20:21:25,141] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:21:25,157] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.460 seconds
[2022-11-12 20:21:34,926] {processor.py:163} INFO - Started process (PID=777) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:21:34,935] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:21:34,935] {logging_mixin.py:109} INFO - [2022-11-12 20:21:34,935] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:21:35,336] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:21:35,356] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 21, 35, 349172, tzinfo=Timezone('UTC')), 'duration': 423}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:21:35,368] {logging_mixin.py:109} INFO - [2022-11-12 20:21:35,368] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:21:35,379] {logging_mixin.py:109} INFO - [2022-11-12 20:21:35,379] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:21:35,386] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.463 seconds
[2022-11-12 20:21:45,221] {processor.py:163} INFO - Started process (PID=795) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:21:45,222] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:21:45,222] {logging_mixin.py:109} INFO - [2022-11-12 20:21:45,222] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:21:45,684] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:21:45,703] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 21, 45, 696451, tzinfo=Timezone('UTC')), 'duration': 433}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:21:45,714] {logging_mixin.py:109} INFO - [2022-11-12 20:21:45,714] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:21:45,723] {logging_mixin.py:109} INFO - [2022-11-12 20:21:45,723] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:21:45,730] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.512 seconds
[2022-11-12 20:21:55,456] {processor.py:163} INFO - Started process (PID=813) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:21:55,457] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:21:55,458] {logging_mixin.py:109} INFO - [2022-11-12 20:21:55,458] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:21:55,884] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:21:55,907] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 21, 55, 898786, tzinfo=Timezone('UTC')), 'duration': 443}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:21:55,920] {logging_mixin.py:109} INFO - [2022-11-12 20:21:55,920] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:21:55,931] {logging_mixin.py:109} INFO - [2022-11-12 20:21:55,931] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:21:55,938] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.486 seconds
[2022-11-12 20:22:05,799] {processor.py:163} INFO - Started process (PID=831) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:22:05,800] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:22:05,801] {logging_mixin.py:109} INFO - [2022-11-12 20:22:05,801] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:22:06,187] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:22:06,206] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 22, 6, 199997, tzinfo=Timezone('UTC')), 'duration': 454}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:22:06,219] {logging_mixin.py:109} INFO - [2022-11-12 20:22:06,219] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:22:06,229] {logging_mixin.py:109} INFO - [2022-11-12 20:22:06,229] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:22:06,247] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.451 seconds
[2022-11-12 20:22:15,997] {processor.py:163} INFO - Started process (PID=848) to work on /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:22:15,998] {processor.py:620} INFO - Processing file /opt/airflow/dags/postgre_create_table.py for tasks to queue
[2022-11-12 20:22:15,999] {logging_mixin.py:109} INFO - [2022-11-12 20:22:15,998] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:22:16,476] {processor.py:632} INFO - DAG(s) dict_keys(['load_to_dwh_v2']) retrieved from /opt/airflow/dags/postgre_create_table.py
[2022-11-12 20:22:16,494] {processor.py:562} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/postgre_create_table.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 553, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/dag_processing/processor.py", line 585, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1753, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1743, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'extract_and_clean_data', 'dag_id': 'load_to_dwh_v2', 'execution_date': None, 'start_date': datetime.datetime(2022, 11, 12, 20, 14, 31, 903427, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2022, 11, 12, 20, 22, 16, 488409, tzinfo=Timezone('UTC')), 'duration': 464}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-11-12 20:22:16,510] {logging_mixin.py:109} INFO - [2022-11-12 20:22:16,509] {dag.py:2389} INFO - Sync 1 DAGs
[2022-11-12 20:22:16,521] {logging_mixin.py:109} INFO - [2022-11-12 20:22:16,521] {dag.py:2914} INFO - Setting next_dagrun for load_to_dwh_v2 to None
[2022-11-12 20:22:16,535] {processor.py:171} INFO - Processing /opt/airflow/dags/postgre_create_table.py took 0.540 seconds
